package org.apache.hadoop.hive.serde2.text.log;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Properties;
import java.util.regex.Pattern;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hive.serde.serdeConstants;
import org.apache.hadoop.hive.serde2.SerDeException;
import org.apache.hadoop.hive.serde2.SerDeSpec;
import org.apache.hadoop.hive.serde2.text.AbstractRegexTextSerDe;
import org.apache.hadoop.hive.serde2.text.AbstractTextSerDe;

/**
 * The Combined Log Log Format is a an ASCII format, available for Web sites but
 * not for FTP sites, and is the default format for Apache HTTP Server. This
 * format is exactly the same as the Common Log Format, with the addition of two
 * more fields.
 *
 * The log file entries produced will look something like this:
 *
 * <pre>
 * 127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] "GET /pb.gif HTTP/1.0" 200 2326 "http://www.example.com/start.html" "Mozilla/4.08 [en] (Win98; I ;Nav)"
 * </pre>
 *
 * The additional fields are:
 * <ol>
 * <li>The "Referer" (sic) HTTP request header. This gives the site that the
 * client reports having been referred from</li>
 * <li>The User-Agent HTTP request header. This is the identifying information
 * that the client browser reports about itself.</li>
 * </ol>
 *
 * <b>Notes:</b>
 *
 * <p>
 * A "hyphen" in the output indicates that the requested piece of information is
 * not available and will be represented as a null value.
 * </p>
 * <p>
 * All fields are terminated with a space.
 * </p>
 * <p>
 * The Hive table definition must map precisely to this format or a
 * {@link SerDeException} is thrown.
 * </p>
 *
 * @see https://httpd.apache.org/docs/current/logs.html#accesslog
 * @see CommonLogFormatSerDe
 */
@SerDeSpec(schemaProps = { serdeConstants.LIST_COLUMNS,
    serdeConstants.SERIALIZATION_ENCODING,
    AbstractTextSerDe.IGNORE_EMPTY_LINES })
public class CombinedLogFormatSerDe extends AbstractRegexTextSerDe {

  private final static String LOG_REGEX =
      "^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(.*)\" "
          + "(\\d{3}) (\\S+) \"(\\S+)\" \"(.*)\"$";

  private static final int EXPECTED_COL_COUNT = 9;

  @Override
  public void initialize(final Configuration configuration,
      final Properties tableProperties) throws SerDeException {
    final Pattern pattern = Pattern.compile(LOG_REGEX);
    super.setPattern(pattern);
    super.initialize(configuration, tableProperties);
    if (EXPECTED_COL_COUNT != getColumnNames().size()) {
      throw new SerDeException(
          "Schema must have 9 columns defined to match log format.");
    }
  }

  /**
   * In the Combined Log Format, a 'null' value is represented with a dash "-".
   * Use the regex to capture the field values and replace any dashes with null
   * values.
   *
   * @param clob The unicode string to deserialize
   * @return A list of strings pulled from the value provided
   * @throws SerDeException If the number of capture groups generated by
   *           applying the regex to the clob value provided does not equal the
   *           number of columns defined in the Hive table
   */
  @Override
  protected List<String> doDeserialize(final String clob)
      throws SerDeException {
    final List<String> fields = super.doDeserialize(clob);
    final List<String> nulledFields = new ArrayList<>(fields.size());
    for (final String field : fields) {
      final String newValue = ("-".equals(field)) ? null : field;
      nulledFields.add(newValue);
    }
    return Collections.unmodifiableList(nulledFields);
  }

}